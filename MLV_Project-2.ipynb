{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLV_Project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP-H7uf32_fh",
        "colab_type": "text"
      },
      "source": [
        "## **Getting the Data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvjMHsJbcL0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Function to load full crash data\n",
        "def load_crash_data(path=\"Full_Crash.csv\"):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "#Function to save updated crash data after extracting useful features\n",
        "def save_crash_data(data_frame):\n",
        "    data_frame.to_csv('Updated_Crash_Data.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTGDh4DJ3R1s",
        "colab_type": "code",
        "outputId": "48526214-383d-4639-e0c9-83925f04f0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#Open Full crash data file\n",
        "crash_data = load_crash_data()\n",
        "crash_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-de194de5eef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrash_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_crash_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcrash_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d9ccdaa0b877>\u001b[0m in \u001b[0;36mload_crash_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Function to load full crash data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_crash_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Full_Crash.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Function to save updated crash data after extracting useful features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Full_Crash.csv' does not exist: b'Full_Crash.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvZkJ0LJMR1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crash_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLbAczi33b4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create new table containing only useful features\n",
        "new_crash_data = crash_data[['Carspeedlimit','Alcohol_Notalcohol', 'DAY_OF_WEEK', 'NIGHT', 'Weather_Condition', 'Young_Notyoung', 'Light_Condition', 'INTERSECTION_TYPE', 'Collision_Type', 'Time_Slicing_Used', 'RURALURBANDESC']].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKYpoa208BuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_crash_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dikiz5-aL_qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check for incomplete rows\n",
        "incomplete_rows = new_crash_data[new_crash_data.isnull().any(axis=1)].head()\n",
        "incomplete_rows\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w02o36ltNhtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Only 5 rows have Null values so just drop them from dataset\n",
        "crash_cleaned = new_crash_data.dropna(subset=[\"Carspeedlimit\"]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXtghsnOMnzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incomplete_rows = crash_cleaned[new_crash_data.isnull().any(axis=1)].head()\n",
        "incomplete_rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brLwQP0x9Bez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save new dataframe into csv_file so Full_Crash doesn't need to be opened\n",
        "save_crash_data(crash_cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5pJSkgIi0wN",
        "colab_type": "text"
      },
      "source": [
        "## **Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7DhtJiXi294",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lng_lat = crash_data[['X', 'Y', 'Carspeedlimit']].copy()\n",
        "lng_lat.head"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VseC8DkjSdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop Null values from dataset\n",
        "lng_lat_prepared = lng_lat.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUp-5usnj_-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lng_lat_prepared.info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPBJQ9DiYtPS",
        "colab_type": "text"
      },
      "source": [
        "The first map of the datapoints show the Longitude and Latitude of the points. Noticably, there is a high concentration of points around major cities and roadways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6mGumA8Ycml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lng_lat_prepared.plot(kind='scatter', x='X', y='Y', alpha = 0.1,\n",
        "            figsize=(10,4))\n",
        "\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Crash Crashes in Virginia')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wXN0Gl4Y6C9",
        "colab_type": "text"
      },
      "source": [
        "The next map uses a heatmap to show the density of crashes by the speedlimit the driver was going. It can now be seen that the higher density crashes occur at lower speed limits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTxmIoudW3eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Heat map of \n",
        "lng_lat_prepared.plot(kind='scatter', x='X', y='Y', alpha = 0.3,\n",
        "            figsize=(10,4), c='Carspeedlimit', cmap=plt.get_cmap(\"hot\"), colorbar=True)\n",
        "\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Heatmap of Crash Crashes in Virginia by SpeedLimit')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esg-2fqqSXAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "#Overlay Scatterplot over highway map of virginia\n",
        "im = plt.imread('va_highways.jpg')\n",
        "implot = plt.imshow(im)\n",
        "\n",
        "pic = Image.open('va_highways.jpg')\n",
        "\n",
        "#Convert from original range to picture size range\n",
        "OldRange_X = np.max(lng_lat_prepared['X']) - np.min(lng_lat_prepared['X']) \n",
        "OldRange_Y = np.max(lng_lat_prepared['Y']) - np.min(lng_lat_prepared['Y']) \n",
        "NewRange_X = pic.size[0]\n",
        "NewRange_Y = -pic.size[1]\n",
        "NewValue_X = (((lng_lat_prepared['X'] - np.min(lng_lat_prepared['X'])) * NewRange_X) / OldRange_X)\n",
        "NewValue_Y = (((lng_lat_prepared['Y'] - np.min(lng_lat_prepared['Y'])) * NewRange_Y) / OldRange_Y) - NewRange_Y\n",
        "\n",
        "plt.scatter(NewValue_X, NewValue_Y, alpha=0.01)\n",
        "plt.xlabel('Longitude Scaled')\n",
        "plt.ylabel('Latitude Scaled')\n",
        "plt.title('Crash Crashes in Virginia Overlay Virginia Highway Map')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OeZ8WRJU_D_",
        "colab_type": "text"
      },
      "source": [
        "The above graph gives insight into where a majority of the crashes are occuring. Most crashes occur on the major highways, which is where a large percentage of drivers drive everyday. Also, a lot of crashes are concentrated around cities because the population density is higher so there are more cars. This means that features pretaining to road type and population density are important factors. This is way the RURALURBANDESC and the Carspeedlimit features were selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-KzYNB9K4I3",
        "colab_type": "text"
      },
      "source": [
        "## **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAsc6aVyPTHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#Function to load full crash data\n",
        "def load_updated_crash_data(path=\"Updated_Crash_Data.csv\"):\n",
        "    return pd.read_csv(path)\n",
        "\n",
        "#Open updated crash data\n",
        "crash_data = load_updated_crash_data()\n",
        "crash_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIZlGUe6aHSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#Split data into categorical and numerical features for processing\n",
        "crash_num = crash_data['Carspeedlimit']\n",
        "crash_cat = crash_data.drop('Carspeedlimit', axis=1)\n",
        "\n",
        "num_attribs = [\"Carspeedlimit\"]\n",
        "cat_attribs = list(crash_cat)\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "crash_prepared = full_pipeline.fit_transform(crash_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmX6dQmHOoCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "small_crash_set = crash_prepared[:8600] # for hyperparamter tuning\n",
        "train_set, test_set = train_test_split(crash_prepared, test_size=0.1, random_state=42)\n",
        "train_small, test_small = train_test_split(small_crash_set, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei3xTxQQbiMJ",
        "colab_type": "text"
      },
      "source": [
        "## **One Class SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dKSArZjfUlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "#Standard GridSearch can't be performed with OneClassSVM so use custom function\n",
        "#Function returns best set of parameters from input grid\n",
        "def gridTune(model, train, test, grid):\n",
        "  best_params = None\n",
        "  best_accuracy = 0\n",
        "  i = 0\n",
        "  for z in ParameterGrid(grid):\n",
        "    model.set_params(**z)\n",
        "    model.fit(train)\n",
        "    y_pred = model.predict(test)\n",
        "    if 1. in y_pred:\n",
        "      accScore = accuracy_score([1] * len(y_pred), y_pred)\n",
        "      if (accScore >= best_accuracy):\n",
        "        best_params = z\n",
        "        best_accuracy = accScore\n",
        "  return best_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EetKtNKtq-Oq",
        "colab_type": "text"
      },
      "source": [
        "**RBF Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfVLAGpech7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_rbf_grid = OneClassSVM(kernel='rbf')\n",
        "\n",
        "#Parameter Grid: gamma, nu\n",
        "grid = {'gamma' : np.logspace(-4,3,5),\n",
        "        'nu' : np.linspace(0.3,0.99,5)}\n",
        "\n",
        "bestParameters = gridTune(clf_rbf_grid, train_small, test_small, grid)\n",
        "print(bestParameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcVAgKSjqZ5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train svm with best parameters\n",
        "clf_rbf = OneClassSVM(kernel=\"rbf\", gamma=bestParameters['gamma'], nu=bestParameters['nu']) \n",
        "clf_rbf.fit(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inLyFLfvrl2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RBF Accuracy\n",
        "y_pred_train_rbf = clf_rbf.predict(train_set)\n",
        "y_pred_test_rbf = clf_rbf.predict(test_set)\n",
        "rbf_train_acc = y_pred_train_rbf[y_pred_train_rbf == 1].size\n",
        "rbf_test_acc = y_pred_test_rbf[y_pred_test_rbf == 1].size\n",
        "\n",
        "print(\"Training Accuracy: \", rbf_train_acc / len(y_pred_train_rbf)) #Training accuracy\n",
        "print(\"Testing Accuracy: \", rbf_test_acc / len(y_pred_test_rbf)) #Testing accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcK8I-oJyqlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RBF confusion matrix\n",
        "confusion_matrix([1] * len(y_pred_test_rbf), y_pred_test_rbf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU_31Vnvy5un",
        "colab_type": "text"
      },
      "source": [
        "The confusion matrix for this classification looks slightly different than the confusion matrices we are used to seeing. This is because all the samples in the dataset represent car crashes. Thus the only possibilites are to calulate true positives (bottom right) or false negatives (bottom left)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLfvXAJNrY6p",
        "colab_type": "text"
      },
      "source": [
        "**Polynomial Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw71m2f9tjFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_poly_grid = OneClassSVM(kernel='poly')\n",
        "\n",
        "#Parameter Grid: gamme, nu, coef0\n",
        "grid = {'gamma' : np.logspace(-4,3,5),\n",
        "        'nu' : np.linspace(0.3,0.99,5),\n",
        "        'coef0' : (0,1)}\n",
        "\n",
        "bestParametersPoly = gridTune(clf_rbf_grid, train_small, test_small, grid)\n",
        "print(bestParametersPoly)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X_4XaKQs-lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train svm with best parameters\n",
        "clf_poly = OneClassSVM(kernel=\"poly\", gamma=bestParametersPoly['gamma'], \n",
        "                       nu=bestParametersPoly['nu'], coef0=bestParametersPoly['coef0']) \n",
        "clf_poly.fit(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxI6gdpptQx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Polynomial Accuracy\n",
        "y_pred_train_poly = clf_poly.predict(train_set)\n",
        "y_pred_test_poly = clf_poly.predict(test_set)\n",
        "poly_train_acc = y_pred_train_poly[y_pred_train_poly == 1].size\n",
        "poly_test_acc = y_pred_test_poly[y_pred_test_poly == 1].size\n",
        "\n",
        "print(\"Training Accuracy: \", poly_train_acc / len(y_pred_train_poly)) #Training accuracy\n",
        "print(\"Testing Accuracy: \", poly_test_acc / len(y_pred_test_poly)) #Testing accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIzqrm7pzlAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Polynomial confusion matrix\n",
        "confusion_matrix([1] * len(y_pred_test_poly), y_pred_test_poly)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-I8sT1HrajD",
        "colab_type": "text"
      },
      "source": [
        "**Linear Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzMKKooTv34V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_lin_grid = OneClassSVM(kernel='linear')\n",
        "\n",
        "#Parameter Grid: gamme, nu\n",
        "grid = {'gamma' : np.logspace(-4,3,5),\n",
        "        'nu' : np.linspace(0.3,0.99,5)}\n",
        "\n",
        "bestParametersLin = gridTune(clf_lin_grid, train_small, test_small, grid)\n",
        "print(bestParametersLin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL_2TFVVv-zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train svm with best parameters\n",
        "clf_lin = OneClassSVM(kernel=\"linear\", gamma=bestParametersPoly['gamma'], \n",
        "                       nu=bestParametersPoly['nu']) \n",
        "clf_lin.fit(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAHgYUWKwgSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linear Accuracy\n",
        "y_pred_train_lin = clf_lin.predict(train_set)\n",
        "y_pred_test_lin = clf_lin.predict(test_set)\n",
        "lin_train_acc = y_pred_train_lin[y_pred_train_lin == 1].size\n",
        "lin_test_acc = y_pred_test_lin[y_pred_test_lin == 1].size\n",
        "\n",
        "print(\"Training Accuracy: \", lin_train_acc / len(y_pred_train_lin)) #Training accuracy\n",
        "print(\"Testing Accuracy: \", lin_test_acc / len(y_pred_test_lin)) #Testing accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WsmgGfuw9pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Linear confusion matrix\n",
        "confusion_matrix([1] * len(y_pred_test_lin), y_pred_test_lin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwlncCXFQvbo",
        "colab_type": "text"
      },
      "source": [
        "After training with the optimal parameters on the entire datset, the rbf and linear kernels achieved the same accuracy of 69.74% on the testing set. It should be noted that the rbf kernel performed slightly better than the linear kernel on the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyE8bf7Cz6ls",
        "colab_type": "text"
      },
      "source": [
        "## **K-Nearest Neighbors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVQGPH6l5mlO",
        "colab_type": "text"
      },
      "source": [
        "With K_Nearest Neighbors you can use novelty detection to determine whether a datapoint is an outlier or not. This is useful with our dataset since we are trying to create a boundary around the data in order to create a threshold for positive samples to be within."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDcapI2l0Cr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "clf_LOF = LocalOutlierFactor(novelty=True, n_neighbors=20, contamination='auto')  #Need to set novelty to True\n",
        "clf_LOF.fit(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZLoD57T1Kg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kNeighbors Accuracy\n",
        "y_pred_LOF = clf_LOF.predict(test_set)\n",
        "LOF_test_acc = y_pred_LOF[y_pred_LOF == 1].size\n",
        "print(\"Testing Accuracy: \", LOF_test_acc / len(y_pred_LOF)) #Testing accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWuzXAdH1Vuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kNeighbors confusion matrix\n",
        "confusion_matrix([1] * len(y_pred_LOF), y_pred_LOF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu4ztYriDfx3",
        "colab_type": "text"
      },
      "source": [
        "## **Isolation Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjmbEB-6DjuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "clf_iso = IsolationForest(n_estimators=10, warm_start=True, behaviour='new', verbose=1, n_jobs=100)\n",
        "clf_iso.fit(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhFjVdaoEAcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#isoForest Accuracy\n",
        "y_pred_iso = clf_iso.predict(test_set)\n",
        "iso_test_acc = y_pred_iso[y_pred_iso == 1].size\n",
        "print(\"Testing Accuracy: \", iso_test_acc / len(y_pred_iso)) #Testing accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TfvdrgXETgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#isoForest confusion matrix\n",
        "confusion_matrix([1] * len(y_pred_iso), y_pred_iso)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wK2FTkERKsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_iso.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}